{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73f86026",
   "metadata": {},
   "source": [
    "# Partially observable Markov decision processes (POMDPs)\n",
    "https://h2r.github.io/pomdp-py/html/  \n",
    "https://github.com/h2r/pomdp-py  \n",
    "https://github.com/namoshizun/PyPOMDP  \n",
    "\n",
    "\n",
    "to read https://solutionspace.blog/2011/12/05/training-a-pomdp-with-python/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ae118f",
   "metadata": {},
   "source": [
    "a POMDP is represented as a tuple $(S,A, T,R,Z,O)$: state set $S$, action set $A$, observation set $Z$\n",
    "## symbol definition\n",
    "**Transition function**: $${\\color{blue} {T(s(t-1)=i, a(t-1)=a, s(t)=j) = p_{i,a}^j = Pr\\{ s(t)=j | s(t-1)=i, a(t-1)=a, h(t-1) \\} }}$$ is probability of ending state $s(t)=j$ at time $t$ if action $a$ is executed in starting state $s(t-1)=i$;\n",
    "\n",
    "**Observation function**:$${\\color{green} {O(a(t-1)=a, s(t)=j, z(t)=\\theta) = p_{a,j}^{\\theta} = Pr\\{ z(t)=\\theta | s(t)=j, s(t-1)=i, a(t-1)=a, h(t-1)\\} }}$$ at time $t$ if action $a$ is performed and the resulting/ending state is $s(t)=j$.\n",
    "\n",
    "**Reward function**: $R(s(t-1)=i, a(t-1)=a)$ (or symbolized as $w_{i,j,\\theta}^a$) is the reward obtained by executing action $a$ in starting state $s(t-1)=i$;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d298f75",
   "metadata": {},
   "source": [
    "## state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c06994b",
   "metadata": {},
   "source": [
    "History information: $h_t = [z(t), a(t-1), h(t-1)] = [z(t), a(t-1), z(t-1), a(t-2), \\dots, z(1), a(0)]$ contains previous actions and observations.\n",
    "\n",
    "Version 1  \n",
    "$\\color{red}{\\pi_j(t) = Pr\\{ s(t)=j | h(t) \\}}$ is probability that current state is $j$;  \n",
    "information-state vector $\\pi = [\\pi_1, \\pi_2, \\cdots, \\pi_N]$;  \n",
    "\n",
    "Version 2  \n",
    "**A belief state** at time $t$ is defined as the posterior probability distribution of being in each state, i.e., $\\color{Purple} {b_t(j) = Pr(s(t) = j|h_t, b_0)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c07e43",
   "metadata": {},
   "source": [
    "## update function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3cbb6a",
   "metadata": {},
   "source": [
    "Version 1  \n",
    "$$ \\begin{aligned}\\color{red}{\\pi_j(t)} & = Pr\\{ s(t)=j | h(t) \\} \\\\\n",
    "& = Pr\\{ s(t)=j | z(t), a(t-1)=a, h(t-1) \\} \\\\\n",
    "& = \\frac{ \n",
    "\tPr\\{ s(t)=j, z(t)=\\theta | a(t-1)=a, h(t-1) \\} \n",
    "}{ \n",
    "\tPr\\{ z(t) = \\theta | a(t-1)=a, h(t-1) \\}\n",
    "} \\\\\n",
    "& = \\frac{\\sum_i \n",
    "\t\\color{red}  {Pr\\{ s(t-1)=i | a(t-1)=a,h(t-1) \\} }\n",
    "\t\\color{blue}  {Pr\\{ s(t)=j | s(t-1)=i, a(t-1)=a, h(t-1) \\} }\n",
    "\t\\color{green} {Pr\\{ z(t)=\\theta | a(t-1)=a, s(t)=j, s(t-1)=i, h(t-1)\\} }\n",
    "}{ \n",
    "\tPr\\{ z(t)=\\theta|a(t-1)=a,h(t-1) \\} \n",
    "} \\\\ \n",
    "& = \\frac{\n",
    "\t\\sum_i \\color{red}{\\pi_i(t-1)}\n",
    "\t\\color{blue} {p_{i,a}^j } \n",
    "\t\\color{green}{p_{a,j}^{\\theta} } \n",
    "}{ \n",
    "\t\\sum_{i,j} \\color{red}{\\pi_i(t-1)} \n",
    "\t\\color{blue}{p_{i,a}^j }\n",
    "\t\\color{green}{p_{a,j}^{\\theta}} \n",
    "} \\\\ \n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ab3696",
   "metadata": {},
   "source": [
    "Version 2  \n",
    "**belief state update function**: means **the belief state $b_t(j)$ of ending status $s(t)=j$ at time $t$** can be computed from the previous belief state $b_{t−1}(i)$ of all status $s(t-1)=i$, using the previous action $a(t−1)=a$ and the current observation $z(t)=\\theta$, i.e.,\n",
    "$$ \\begin{aligned}\n",
    "\\color{Purple}{b_t(j)} & = \\color{Purple}{b_t(s(t)=j)} \\\\\n",
    "& = \\frac{\n",
    "\t{\\color{green}{O(a(t−1)=a, s(t)=j, z(t)=\\theta)}} \n",
    "\t\\sum_{i} {\\color{blue}{T(s(t-1)=i, a(t−1)=a, s(t)=j)}} \n",
    "\t{\\color{Purple}{b_{t−1}(s(t-1)=i)}}\n",
    "}{\n",
    "\tPr(z_t|b_{t−1}, a_{t−1})\n",
    "} \\\\\n",
    "& = \\frac{\n",
    "\t\\color{green}{O(a(t−1)=a, s(t)=j, z(t)=\\theta)} \n",
    "\t\\sum_{i}\\color{blue}{T(s(t-1)=i, a(t−1)=a, s(t)=j)} \n",
    "\t\\color{Purple}{b_{t−1}(s(t-1)=i)}\n",
    "}{ \n",
    "\t\\sum_{j} {\\color{green}{O(a(t-1)=a,s(t)=j,z(t)=\\theta)}}  \n",
    "\t\\sum_{i} {\\color{blue}{T(s(t-1)=i,a(t-1)=a,s(t)=j)}} \n",
    "\t\\color{Purple}{b_{t-1}(s(t-1)=i)} \n",
    "} \\\\\n",
    "& = \\frac{\n",
    "\t{\\color{green}{Pr(z(t)=\\theta|a(t−1)=a, s(t)=j)} }\n",
    "\t\\sum_{i} {\\color{blue}{Pr(s(t)=j|s(t-1)=i, a(t-1)=a)} } \n",
    "\t{\\color{Purple}{b_{t−1}(i)}}\n",
    "}{\n",
    "\t\\sum_{j}\\left\\{  {\\color{green}{Pr(z(t)=\\theta | a(t-1)=a, s(t)=j)}}\n",
    "\t\\sum_{i} {\\color{blue}{Pr(s(t)=j | s(t-1)=i, a(t-1)=a) }} \n",
    "\t{\\color{Purple}{b_{t-1}(i) }} \\right\\}\n",
    "} \\\\\n",
    "& = \\frac{\n",
    "\t{\\color{green}{ p_{a,j}^{\\theta} } }\n",
    "\t\\sum_{i} {\\color{blue}{ p_{i,a}^j } } \n",
    "\t{\\color{Purple}{b_{t−1}(i)}}\n",
    "}{\n",
    "\t\\sum_{j}\\left\\{  {\\color{green}{ p_{a,j}^{\\theta} }}\n",
    "\t\\sum_{i} {\\color{blue}{ p_{i,a}^j }} \n",
    "\t{\\color{Purple}{b_{t-1}(i) }} \\right\\}\n",
    "} \\\\\n",
    "& = \\frac{\n",
    "\t\\sum_{i} {\\color{Purple}{b_{t−1}(i)}}{\\color{blue}{ p_{i,a}^j } } {\\color{green}{ p_{a,j}^{\\theta} } }\n",
    "}{\n",
    "\t\\sum_{i,j} {\\color{Purple}{b_{t−1}(i)}}{\\color{blue}{ p_{i,a}^j } } {\\color{green}{ p_{a,j}^{\\theta} } }\n",
    "} \\\\\n",
    "& = \\tau (b_{t−1}, a_{t−1}, z_t)(j) \\\\\n",
    "\\end{aligned} $$\n",
    "\n",
    ">- $Pr(z_t|b_{t-1}, a_{t-1})$ in the second row, acts as a\n",
    "normalizing constant such that $b_t$ remains a probability distribution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2663afec",
   "metadata": {},
   "source": [
    "**Summary**: the update function is essentially transition probability of state vector, i.e., \n",
    "$$\\pi(t-1) \\to \\pi(t) = \\Gamma(\\pi(t-1)|a(t-1)=a,z(t)=\\theta)$$\n",
    "$$b_{t-1} \\to b_{t} = \\Gamma(b_{t-1}|a(t-1)=a,z(t)=\\theta)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4545c80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49674cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b42ec1d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b85dfb2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6d83f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "70d1a62a",
   "metadata": {},
   "source": [
    "maximum expected reward \n",
    "$$\\begin{aligned}\n",
    "V_n(\\pi) & = \\max_{a \\in A} \\left\\{ \\sum_i \\pi_i \\color{red}{\\sum_j p_{i,j}^a \\sum_{\\theta} r_{j,\\theta}^a} \\left[ \\color{red}{w_{i,j,\\theta}^a} + V_{n-1}\\left(T(\\pi|a,\\theta)\\right)\\right] \\right\\} \\\\\n",
    "& = \\max_{a \\in A} \\left\\{ \\sum_i \\pi_i \\color{red}{q_i^a} + \\sum_{i,j,\\theta} \\color{blue}{\\pi_i p_{i,j}^a r_{j,\\theta}^a} \n",
    "V_{n-1}\\left(T(\\pi|a,\\theta)\\right) \\right\\} \\\\\n",
    "& = \\max_{a \\in A} \\left\\{ \\sum_i \\pi_i q_i^a + \\sum_{\\theta} \\color{blue}{pr\\{\\theta|\\pi,a\\}} \n",
    "V_{n-1}\\left(T(\\pi|a,\\theta)\\right) \\right\\} \\\\\n",
    "\\end{aligned}$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af359098",
   "metadata": {},
   "source": [
    "$\\color{blue} {pr\\{\\theta|\\pi,a\\}} $ is probability of next observing output $\\theta$ if the current information vector is $\\pi$ and the next action selected is $a$, i.e., $Pr(z(t)=\\theta|\\pi(t-1), a(t-1)=a)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7993b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "224.4px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
